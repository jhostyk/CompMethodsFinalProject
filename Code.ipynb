{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Ray: Anomaly-Detection and Classification\n",
    "\n",
    "### Computational Methods II Final Project\n",
    "\n",
    "#### Sarah Yam and Joseph Hostyk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import inspect\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the code from the Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.size())\n",
    "print(train_dataset.train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.test_data.size())\n",
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 1876\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModelStatic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModelStatic, self).__init__()\n",
    "\n",
    "        # Convolution 1\n",
    "        #### your code here ###\n",
    "        self.cnn1 = torch.nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5, stride = 1,\n",
    "                                    padding = 0)#,dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        # ReLU 1\n",
    "        #### your code here ###\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "\n",
    "        # Max pool 1\n",
    "        #### your code here ###\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size = 2)#, stride=None, padding=0, dilation=1,\n",
    "                                           #return_indices=False, ceil_mode=False)\n",
    "\n",
    "        # Convolution 2\n",
    "        #### your code here ###\n",
    "        self.cnn2 = torch.nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride = 1,\n",
    "                                    padding = 0)#,dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        # RelU 2\n",
    "        #### your code here ###\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "        # Max pool 2\n",
    "        #### your code here ###\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size = 2)\n",
    "\n",
    "        # Fully connected 1 (readout)\n",
    "        #### your code here ###\n",
    "        self.fc1 = nn.Linear(in_features = 512, out_features = 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # Convolution 2 \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        # Resize\n",
    "        # Reshape your output layer to fit into the final layer of the FCNN\n",
    "        # Original size: (batch_size, 32, 4, 4)\n",
    "        # out.size(0): batch_size\n",
    "        # New out size: (batch_size, 32*4*4)\n",
    "        #### your code here ###\n",
    "        out = out.view(out.size(0), 512)\n",
    "        \n",
    "        #### end code here ###\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 24, 24]             416\n",
      "              ReLU-2           [-1, 16, 24, 24]               0\n",
      "         MaxPool2d-3           [-1, 16, 12, 12]               0\n",
      "            Conv2d-4             [-1, 32, 8, 8]          12,832\n",
      "              ReLU-5             [-1, 32, 8, 8]               0\n",
      "         MaxPool2d-6             [-1, 32, 4, 4]               0\n",
      "            Linear-7                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 18,378\n",
      "Trainable params: 18,378\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.19\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#### your code here ###\n",
    "cnn = CNNModelStatic()\n",
    "summary(cnn, input_size=(1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Dynamic CNN\n",
    "The above code is great for getting an idea of how to build a model. But in production we would want to be able to iterate through multiple different architectural choices like number of layers, filter sizes, pooling kernels, strides, activation functions, etc. In order to be able to do this we need to build our model using arguments which specify the architecture and loops. Otherwise we'd have to explicitly type out every layer of our model, for every change we wanted to implement.\n",
    "\n",
    "Now just in case any of your are getting flashbacks to lab 4, not to worry. I've implemented most of the function for you. You're encouraged to walk through it to understand what's happening. **All you have to do is implement the method `calculateFinalOutputSize` that calculates the size of the final output, which is needed to calculate the size of the final FCNN layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModelDynamic(nn.Module):\n",
    "    def __init__(self, input_shape, n_classes,\n",
    "                 in_channels_list, out_channels_list,\n",
    "                 kernel_size_list, stride_list,\n",
    "                 padding_list, pool_kernel_list,\n",
    "                 pool_stride_list,\n",
    "                 pooling_list, activations_list):\n",
    "        super(CNNModelDynamic, self).__init__()\n",
    "        localArgs = locals().items()\n",
    "        argLens = set()\n",
    "        ignoredArgs = ['self', \"__class__\", \"input_shape\", \"n_classes\"]\n",
    "        for argName, arg in localArgs:\n",
    "            if argName not in ignoredArgs:\n",
    "                argLens.add(len(arg))\n",
    "        assert len(argLens) == 1, (\"mismatch in lengths of arguments.\"\n",
    "                                   \"All params for each layer must be specified\")\n",
    "        finalOutputSize = self.calculateFinalOutputSize(input_shape,kernel_size_list, stride_list,\n",
    "                                         padding_list, pool_kernel_list, pool_stride_list)\n",
    "        modules = list()\n",
    "        for layerIdx in range(0, argLens.pop()):\n",
    "            modules.append(nn.Conv2d(in_channels = in_channels_list[layerIdx],\n",
    "                                 out_channels = out_channels_list[layerIdx],\n",
    "                                 kernel_size = kernel_size_list[layerIdx],\n",
    "                                 stride = stride_list[layerIdx],\n",
    "                                 padding = padding_list[layerIdx]))\n",
    "            modules.append(activations_list[layerIdx])\n",
    "            modules.append(pooling_list[layerIdx](kernel_size = pool_kernel_list[layerIdx],\n",
    "                                                  stride = pool_stride_list[layerIdx]))\n",
    "        self.convolutions = nn.Sequential(*modules)\n",
    "        self.finalLayer = nn.Linear(finalOutputSize**2*out_channels_list[-1], n_classes)\n",
    "        \n",
    "    def outputFromConvLayer(self, w, k, p, s):\n",
    "        return (w-k+2*p)/float(s) + 1\n",
    "    \n",
    "    def outputFromPoolLayer(self, w, k, s):\n",
    "        return (w-k)/float(s) + 1\n",
    "    \n",
    "    def calculateFinalOutputSize(self, input_shape, kernel_size_list, stride_list,\n",
    "                                 padding_list, pool_kernel_list, pool_stride_list):\n",
    "        \"\"\"\n",
    "        Calculates the shape of the final output assuming that every conv layer is followed\n",
    "        by a pooling layer.\n",
    "        \"\"\"\n",
    "         #### your code here ###\n",
    "        currentInput = input_shape\n",
    "        for i in range(len(kernel_size_list)):\n",
    "            currentInput = self.outputFromConvLayer(currentInput, kernel_size_list[i], padding_list[i], stride_list[i])\n",
    "            currentInput = self.outputFromPoolLayer(currentInput, pool_kernel_list[i], pool_stride_list[i])\n",
    "        finalOutputShape = currentInput\n",
    "        \n",
    "        print(\"Final shape is\", int(finalOutputShape))\n",
    "        \n",
    "         #### end code here ###\n",
    "        return(int(finalOutputShape))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.convolutions(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.finalLayer(out)\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Model Summary\n",
    "Using the summary function from torchsummary print out the layers, shapes, and number of parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape is 4\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 24, 24]             416\n",
      "              ReLU-2           [-1, 16, 24, 24]               0\n",
      "         MaxPool2d-3           [-1, 16, 12, 12]               0\n",
      "            Conv2d-4             [-1, 32, 8, 8]          12,832\n",
      "              ReLU-5             [-1, 32, 8, 8]               0\n",
      "         MaxPool2d-6             [-1, 32, 4, 4]               0\n",
      "            Linear-7                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 18,378\n",
      "Trainable params: 18,378\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.19\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#### your code here ###\n",
    "cnnDynamicOG = CNNModelDynamic(input_shape = 28, n_classes = 10,\n",
    "                 in_channels_list = [1, 16], out_channels_list = [16, 32],\n",
    "                 kernel_size_list = [5, 5], stride_list = [1, 1],\n",
    "                 padding_list = [0,0], pool_kernel_list = [2, 2],\n",
    "                 pool_stride_list = [2, 2],\n",
    "                 pooling_list = [nn.MaxPool2d, nn.MaxPool2d], activations_list = [nn.ReLU(), nn.ReLU()])\n",
    "summary(cnnDynamicOG, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Dynamic CNN\n",
    "Now we can train our model. First train the original model implemented above. It shoud train just fine and achieve decent accuracy. \n",
    "\n",
    "1. Your first task is to implement early stopping by keeping track of your best accuracy and stopping training if accuracy doesn't improve after 3 checks. I suggest that you check your evaluation accuracy every 50 iterations unless you have a GPU then by all means check whenever you want. Hell, check twice an iteration. Ain't nothing stopping you with a GPU. Once your best model is found, quit out and stop running. This is where you'd usually save a model, but don't worry about doing that.\n",
    "\n",
    "2. Your second task is to experiment with different configurations. Try at least two architectural changes (depth, convolution layers, channels, strides, **optimization**, average pooling, etc) and record some observations about model performance for your two configurations. I would suggest using Adam as an optimization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doTheThing(model, optimizer):\n",
    "    numIterations = 0\n",
    "    bestAccuracy = 0\n",
    "    patience = 2 # how many times should we be ok with our accuracy not increasing?\n",
    "    checksWithoutIncrease = 0\n",
    "    num_epochs = 5 # Change later\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Load images\n",
    "            images = images.requires_grad_()\n",
    "\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get output/logits\n",
    "            outputs = model.forward(images)\n",
    "\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            numIterations += 1\n",
    "            if numIterations % 50 == 0:\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Iterate through test dataset\n",
    "                for images, labels in test_loader:\n",
    "                    # Load images\n",
    "                    images = images.requires_grad_()\n",
    "\n",
    "                    # Forward pass only to get logits/output\n",
    "                    outputs = model.forward(images)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    # Total number of labels\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                    # Total correct predictions\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * correct / total\n",
    "                # Check if early stopping criteria are met\n",
    "                #### your code here ###\n",
    "\n",
    "                if accuracy > bestAccuracy:\n",
    "                    bestAccuracy = accuracy\n",
    "                    checksWithoutIncrease = 0\n",
    "                else:\n",
    "                    checksWithoutIncrease += 1\n",
    "                    print(\"\\tGone {} rounds without increasing:\".format(checksWithoutIncrease))\n",
    "\n",
    "                #### end code here ###\n",
    "                print('\\tIteration: {}. Loss: {}. Testing Accuracy: {}'.format(numIterations, loss.item(), accuracy))\n",
    "        # remember, early stopping is qutting out of all training.\n",
    "        #### your code here ###\n",
    "                if checksWithoutIncrease > patience:\n",
    "                    print(\"We did not increase accuracy over the past 3 rounds. Quitting!\")\n",
    "                    return bestAccuracy, numIterations * (epoch + 1)\n",
    "        #### end code here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape is 4\n"
     ]
    }
   ],
   "source": [
    "cnnDynamicOG = CNNModelDynamic(input_shape = 28, n_classes = 10,\n",
    "                 in_channels_list = [1, 16], out_channels_list = [16, 32],\n",
    "                 kernel_size_list = [5, 5], stride_list = [1, 1],\n",
    "                 padding_list = [0,0], pool_kernel_list = [2, 2],\n",
    "                 pool_stride_list = [2, 2],\n",
    "                 pooling_list = [nn.MaxPool2d, nn.MaxPool2d], activations_list = [nn.ReLU(), nn.ReLU()])\n",
    "optimizerSGD = torch.optim.SGD(cnnDynamicOG.parameters(), lr=learning_rate)\n",
    "optimizerAdam = torch.optim.Adam(cnnDynamicOG.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape is 1\n"
     ]
    }
   ],
   "source": [
    "cnnDynamiclargerKernels = CNNModelDynamic(input_shape = 28, n_classes = 10,\n",
    "                 in_channels_list = [1, 16], out_channels_list = [16, 32],\n",
    "                 kernel_size_list = [8, 8], stride_list = [1, 1],\n",
    "                 padding_list = [0,0], pool_kernel_list = [2, 2],\n",
    "                 pool_stride_list = [2, 2],\n",
    "                 pooling_list = [nn.MaxPool2d, nn.MaxPool2d], activations_list = [nn.ReLU(), nn.ReLU()])\n",
    "optimizerSGDlargerKernels = torch.optim.SGD(cnnDynamiclargerKernels.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnDynamiclargerKernels = CNNModelDynamic(input_shape = 28, n_classes = 10,\n",
    "                 in_channels_list = [1, 16], out_channels_list = [16, 32],\n",
    "                 kernel_size_list = [8, 8], stride_list = [1, 1],\n",
    "                 padding_list = [0,0], pool_kernel_list = [2, 2],\n",
    "                 pool_stride_list = [2, 2],\n",
    "                 pooling_list = [nn.MaxPool2d, nn.MaxPool2d], activations_list = [nn.ReLU(), nn.ReLU()])\n",
    "optimizerSGDlargerKernels = torch.optim.SGD(cnnDynamiclargerKernels.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\tIteration: 50. Loss: 2.261282444000244. Testing Accuracy: 13\n",
      "\tIteration: 100. Loss: 2.19022274017334. Testing Accuracy: 31\n",
      "\tIteration: 150. Loss: 2.08729887008667. Testing Accuracy: 49\n",
      "\tIteration: 200. Loss: 1.8707693815231323. Testing Accuracy: 56\n",
      "\tIteration: 250. Loss: 1.678735375404358. Testing Accuracy: 64\n",
      "\tIteration: 300. Loss: 1.2326034307479858. Testing Accuracy: 72\n",
      "\tIteration: 350. Loss: 0.9652111530303955. Testing Accuracy: 74\n",
      "\tIteration: 400. Loss: 0.6076298356056213. Testing Accuracy: 77\n",
      "\tIteration: 450. Loss: 0.7554090619087219. Testing Accuracy: 79\n",
      "\tIteration: 500. Loss: 0.6046813726425171. Testing Accuracy: 80\n",
      "\tIteration: 550. Loss: 0.5280731320381165. Testing Accuracy: 81\n",
      "\tGone 1 rounds without increasing:\n",
      "\tIteration: 600. Loss: 0.48492884635925293. Testing Accuracy: 81\n",
      "Epoch: 1\n",
      "\tIteration: 650. Loss: 0.43832606077194214. Testing Accuracy: 82\n",
      "\tGone 1 rounds without increasing:\n",
      "\tIteration: 700. Loss: 0.34086087346076965. Testing Accuracy: 82\n",
      "\tIteration: 750. Loss: 0.34039852023124695. Testing Accuracy: 83\n",
      "\tGone 1 rounds without increasing:\n",
      "\tIteration: 800. Loss: 0.3547576665878296. Testing Accuracy: 83\n",
      "\tIteration: 850. Loss: 0.4207109808921814. Testing Accuracy: 84\n",
      "\tGone 1 rounds without increasing:\n",
      "\tIteration: 900. Loss: 0.36036521196365356. Testing Accuracy: 84\n",
      "\tGone 2 rounds without increasing:\n",
      "\tIteration: 950. Loss: 0.22501316666603088. Testing Accuracy: 84\n",
      "\tIteration: 1000. Loss: 0.22273188829421997. Testing Accuracy: 85\n",
      "\tGone 1 rounds without increasing:\n",
      "\tIteration: 1050. Loss: 0.4332292079925537. Testing Accuracy: 85\n",
      "\tGone 2 rounds without increasing:\n",
      "\tIteration: 1100. Loss: 0.26983797550201416. Testing Accuracy: 85\n",
      "\tIteration: 1150. Loss: 0.22789140045642853. Testing Accuracy: 86\n",
      "\tGone 1 rounds without increasing:\n",
      "\tIteration: 1200. Loss: 0.26331979036331177. Testing Accuracy: 86\n",
      "Epoch: 2\n",
      "\tGone 2 rounds without increasing:\n",
      "\tIteration: 1250. Loss: 0.26977255940437317. Testing Accuracy: 85\n",
      "\tGone 3 rounds without increasing:\n",
      "\tIteration: 1300. Loss: 0.30708521604537964. Testing Accuracy: 85\n",
      "We did not increase accuracy over the past 3 rounds. Quitting!\n"
     ]
    }
   ],
   "source": [
    "# bestAccuracyOriginal, totalIterationsOriginal = doTheThing(cnnDynamicOG, optimizerSGD)\n",
    "# bestAccuracyWithAdam, totalIterationsWithAdam = doTheThing(cnnDynamicOG, optimizerAdam)\n",
    "bestAccuracyWithLargerKernels, totalIterationsWithLargerKernels = doTheThing(cnnDynamiclargerKernels, optimizerSGDlargerKernels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the original settings, the best accuracy achieved was 85, after 1900 iterations.\n",
      "Using Adam as the optimizer, the best accuracy achieved was 93, after 550 iterations.\n",
      "With a larger kernel size, the best accuracy achieved was 86, after 3900 iterations.\n"
     ]
    }
   ],
   "source": [
    "print(\"With the original settings, the best accuracy achieved was {}, after {} iterations.\".format(bestAccuracyOriginal, totalIterationsOriginal))\n",
    "print(\"Using Adam as the optimizer, the best accuracy achieved was {}, after {} iterations.\".format(bestAccuracyWithAdam, totalIterationsWithAdam))\n",
    "print(\"With a larger kernel size, the best accuracy achieved was {}, after {} iterations.\".format(bestAccuracyWithLargerKernels, totalIterationsWithLargerKernels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Computational Methods)",
   "language": "python",
   "name": "cm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
