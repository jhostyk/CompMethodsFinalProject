{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Ray: Anomaly-Detection and Classification\n",
    "\n",
    "### Computational Methods II Final Project\n",
    "\n",
    "#### Sarah Yam and Joseph Hostyk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import inspect\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get labels:\n",
    "def getPatientInfo(patientDataFile):\n",
    "    \n",
    "    patientDataDict = defaultdict(dict)\n",
    "    classificationsToPatients = defaultdict(set)\n",
    "    \n",
    "    with open(patientDataFile, \"r\") as patients:\n",
    "        header = patients.readline().strip().split(\",\")\n",
    "        for patient in patients:\n",
    "            \n",
    "            # We're only keeping frontal (78k), leaving out lateral (10k)\n",
    "            \n",
    "            if \"lateral\" not in patient:\n",
    "            \n",
    "                patient = dict(zip(header, patient.strip().split(\",\")))\n",
    "                ID = patient[\"Patient ID\"]\n",
    "                path = patient[\"Path\"]\n",
    "                \n",
    "                classificationRow = [column for column in patient if patient[column] == \"1\" and column != \"Sum per Row\"]\n",
    "\n",
    "                # Might be 'No Finding' and 'Support Devices'. In which case, we want the last option.\n",
    "                # Otherwise, there should just be one label. In which case we want the last option.\n",
    "                try:\n",
    "                    classification = classificationRow[-1]\n",
    "                    if len(classificationRow) > 1 and classificationRow != ['No Finding', 'Support Devices']:\n",
    "                        print(classificationRow)\n",
    "                    patientDataDict[ID][\"Path\"] = path\n",
    "                    patientDataDict[ID][\"Classification\"] = classification\n",
    "                    \n",
    "                    classificationsToPatients[classification].add(ID)\n",
    "\n",
    "                # The final row of the file is just a tally of the columns.\n",
    "                except IndexError as e:\n",
    "                    continue\n",
    "                    \n",
    "    return patientDataDict, classificationsToPatients\n",
    "\n",
    "# will run tests using my set 0 partition (I made 10 partitions, so each set has about ~8k images)\n",
    "# partitions were done based on the last digit in the patient ID [0 - 9], so it's mildly randomized\n",
    "\n",
    "# current file path to set0 objects: ./set0/Subsetted/train/patients[0 - 9]\n",
    "# file path to set0 patient data: ./Subset0.csv \n",
    "\n",
    "# file path to my actual, full subset: ./SubPatients/train/patients[0 - 9]\n",
    "# name of datafile in my directory (I'll push it later today): SubsetPatients.csv\n",
    "\n",
    "patientDataFile = \"Subset0.csv\"\n",
    "#patientDataFile = \"SubsetPatients.csv\"\n",
    "allPatientDataDict, classificationsToPatients = getPatientInfo(patientDataFile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPatientDataDict\n",
    "# classificationsToPatients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split each disease into 80/20\n",
    "\n",
    "def splitData(classificationsToPatients):\n",
    "    \n",
    "    trainNames = []\n",
    "    testNames = []\n",
    "    \n",
    "    trainPercentage = 0.8\n",
    "    \n",
    "    for classification, patientsWithThatClassification in classificationsToPatients.items():\n",
    "        \n",
    "        total = len(patientsWithThatClassification)\n",
    "        trainAmount = int(trainPercentage * total)\n",
    "        \n",
    "        print(\"There are {} in {}.\".format(total, classification))\n",
    "        \n",
    "        hm = list(patientsWithThatClassification)\n",
    "        \n",
    "        random.shuffle(hm)\n",
    "        \n",
    "        trainNamesForThisClassification = hm[:trainAmount]\n",
    "        testNamesForThisClassification = hm[trainAmount:]\n",
    "        \n",
    "        \n",
    "        trainNames += trainNamesForThisClassification\n",
    "        testNames += testNamesForThisClassification\n",
    "        \n",
    "\n",
    "    return trainNames, testNames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNames, testNames = splitData(classificationsToPatients)\n",
    "print(\"We're left with {} train and {} test.\".format(len(trainNames), len(testNames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write them out:\n",
    "# with open(\"test.txt\", \"w\") as out:\n",
    "#     out.write(\"\\n\".join(testNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\" dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, names, allPatientsDataDict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            names (string): names\n",
    "        \"\"\"\n",
    "        self.names = names\n",
    "        self.patientInfo = allPatientsDataDict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        individualName = self.names[index]\n",
    "        \n",
    "        \n",
    "        individualDisease = self.patientInfo[individualName][\"Classification\"]\n",
    "        individuaPath = self.patientInfo[individualName][\"Path\"]\n",
    "        \n",
    "        \n",
    "        image = Image.open(individuaPath)\n",
    "        pixelArray = np.array(image)\n",
    "        \n",
    "\n",
    "        patientInfo = {\"classification\": individualDisease, \"image\": pixelArray}\n",
    "\n",
    "        return patientInfo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(trainNames, allPatientsDataDict)\n",
    "test_dataset = ImageDataset(testNames, allPatientsDataDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 1876\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the code from the Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.train_data.size())\n",
    "print(train_dataset.train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.test_data.size())\n",
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 1876\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Dynamic CNN\n",
    "The above code is great for getting an idea of how to build a model. But in production we would want to be able to iterate through multiple different architectural choices like number of layers, filter sizes, pooling kernels, strides, activation functions, etc. In order to be able to do this we need to build our model using arguments which specify the architecture and loops. Otherwise we'd have to explicitly type out every layer of our model, for every change we wanted to implement.\n",
    "\n",
    "Now just in case any of your are getting flashbacks to lab 4, not to worry. I've implemented most of the function for you. You're encouraged to walk through it to understand what's happening. **All you have to do is implement the method `calculateFinalOutputSize` that calculates the size of the final output, which is needed to calculate the size of the final FCNN layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModelDynamic(nn.Module):\n",
    "    def __init__(self, input_shape, n_classes,\n",
    "                 in_channels_list, out_channels_list,\n",
    "                 kernel_size_list, stride_list,\n",
    "                 padding_list, pool_kernel_list,\n",
    "                 pool_stride_list,\n",
    "                 pooling_list, activations_list):\n",
    "        super(CNNModelDynamic, self).__init__()\n",
    "        localArgs = locals().items()\n",
    "        argLens = set()\n",
    "        ignoredArgs = ['self', \"__class__\", \"input_shape\", \"n_classes\"]\n",
    "        for argName, arg in localArgs:\n",
    "            if argName not in ignoredArgs:\n",
    "                argLens.add(len(arg))\n",
    "        assert len(argLens) == 1, (\"mismatch in lengths of arguments.\"\n",
    "                                   \"All params for each layer must be specified\")\n",
    "        finalOutputSize = self.calculateFinalOutputSize(input_shape,kernel_size_list, stride_list,\n",
    "                                         padding_list, pool_kernel_list, pool_stride_list)\n",
    "        modules = list()\n",
    "        for layerIdx in range(0, argLens.pop()):\n",
    "            modules.append(nn.Conv2d(in_channels = in_channels_list[layerIdx],\n",
    "                                 out_channels = out_channels_list[layerIdx],\n",
    "                                 kernel_size = kernel_size_list[layerIdx],\n",
    "                                 stride = stride_list[layerIdx],\n",
    "                                 padding = padding_list[layerIdx]))\n",
    "            modules.append(activations_list[layerIdx])\n",
    "            modules.append(pooling_list[layerIdx](kernel_size = pool_kernel_list[layerIdx],\n",
    "                                                  stride = pool_stride_list[layerIdx]))\n",
    "        self.convolutions = nn.Sequential(*modules)\n",
    "        self.finalLayer = nn.Linear(finalOutputSize**2*out_channels_list[-1], n_classes)\n",
    "        \n",
    "    def outputFromConvLayer(self, w, k, p, s):\n",
    "        return (w-k+2*p)/float(s) + 1\n",
    "    \n",
    "    def outputFromPoolLayer(self, w, k, s):\n",
    "        return (w-k)/float(s) + 1\n",
    "    \n",
    "    def calculateFinalOutputSize(self, input_shape, kernel_size_list, stride_list,\n",
    "                                 padding_list, pool_kernel_list, pool_stride_list):\n",
    "        \"\"\"\n",
    "        Calculates the shape of the final output assuming that every conv layer is followed\n",
    "        by a pooling layer.\n",
    "        \"\"\"\n",
    "         #### your code here ###\n",
    "        currentInput = input_shape\n",
    "        for i in range(len(kernel_size_list)):\n",
    "            currentInput = self.outputFromConvLayer(currentInput, kernel_size_list[i], padding_list[i], stride_list[i])\n",
    "            currentInput = self.outputFromPoolLayer(currentInput, pool_kernel_list[i], pool_stride_list[i])\n",
    "        finalOutputShape = currentInput\n",
    "        \n",
    "#         print(\"Final shape is\", int(finalOutputShape))\n",
    "        \n",
    "         #### end code here ###\n",
    "        return(int(finalOutputShape))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.convolutions(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.finalLayer(out)\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Model Summary\n",
    "Using the summary function from torchsummary print out the layers, shapes, and number of parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your code here ###\n",
    "cnnDynamicOG = CNNModelDynamic(input_shape = 28, n_classes = 10,\n",
    "                 in_channels_list = [1, 16], out_channels_list = [16, 32],\n",
    "                 kernel_size_list = [5, 5], stride_list = [1, 1],\n",
    "                 padding_list = [0,0], pool_kernel_list = [2, 2],\n",
    "                 pool_stride_list = [2, 2],\n",
    "                 pooling_list = [nn.MaxPool2d, nn.MaxPool2d], activations_list = [nn.ReLU(), nn.ReLU()])\n",
    "summary(cnnDynamicOG, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Dynamic CNN\n",
    "Now we can train our model. First train the original model implemented above. It shoud train just fine and achieve decent accuracy. \n",
    "\n",
    "1. Your first task is to implement early stopping by keeping track of your best accuracy and stopping training if accuracy doesn't improve after 3 checks. I suggest that you check your evaluation accuracy every 50 iterations unless you have a GPU then by all means check whenever you want. Hell, check twice an iteration. Ain't nothing stopping you with a GPU. Once your best model is found, quit out and stop running. This is where you'd usually save a model, but don't worry about doing that.\n",
    "\n",
    "2. Your second task is to experiment with different configurations. Try at least two architectural changes (depth, convolution layers, channels, strides, **optimization**, average pooling, etc) and record some observations about model performance for your two configurations. I would suggest using Adam as an optimization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doTheThing(model, optimizer):\n",
    "    numIterations = 0\n",
    "    bestAccuracy = 0\n",
    "    patience = 2 # how many times should we be ok with our accuracy not increasing?\n",
    "    checksWithoutIncrease = 0\n",
    "    num_epochs = 5 # Change later\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Load images\n",
    "            images = images.requires_grad_()\n",
    "\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get output/logits\n",
    "            outputs = model.forward(images)\n",
    "\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            numIterations += 1\n",
    "            if numIterations % 50 == 0:\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Iterate through test dataset\n",
    "                for images, labels in test_loader:\n",
    "                    # Load images\n",
    "                    images = images.requires_grad_()\n",
    "\n",
    "                    # Forward pass only to get logits/output\n",
    "                    outputs = model.forward(images)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    # Total number of labels\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                    # Total correct predictions\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * correct / total\n",
    "                # Check if early stopping criteria are met\n",
    "                #### your code here ###\n",
    "\n",
    "                if accuracy > bestAccuracy:\n",
    "                    bestAccuracy = accuracy\n",
    "                    checksWithoutIncrease = 0\n",
    "                else:\n",
    "                    checksWithoutIncrease += 1\n",
    "                    print(\"\\tGone {} rounds without increasing:\".format(checksWithoutIncrease))\n",
    "\n",
    "                #### end code here ###\n",
    "                print('\\tIteration: {}. Loss: {}. Testing Accuracy: {}'.format(numIterations, loss.item(), accuracy))\n",
    "        # remember, early stopping is qutting out of all training.\n",
    "        #### your code here ###\n",
    "                if checksWithoutIncrease > patience:\n",
    "                    print(\"We did not increase accuracy over the past 3 rounds. Quitting!\")\n",
    "                    return bestAccuracy, numIterations * (epoch + 1)\n",
    "        #### end code here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnDynamicOG = CNNModelDynamic(input_shape = 28, n_classes = 10,\n",
    "                 in_channels_list = [1, 16], out_channels_list = [16, 32],\n",
    "                 kernel_size_list = [5, 5], stride_list = [1, 1],\n",
    "                 padding_list = [0,0], pool_kernel_list = [2, 2],\n",
    "                 pool_stride_list = [2, 2],\n",
    "                 pooling_list = [nn.MaxPool2d, nn.MaxPool2d], activations_list = [nn.ReLU(), nn.ReLU()])\n",
    "optimizerSGD = torch.optim.SGD(cnnDynamicOG.parameters(), lr=learning_rate)\n",
    "optimizerAdam = torch.optim.Adam(cnnDynamicOG.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnDynamiclargerKernels = CNNModelDynamic(input_shape = 28, n_classes = 10,\n",
    "                 in_channels_list = [1, 16], out_channels_list = [16, 32],\n",
    "                 kernel_size_list = [8, 8], stride_list = [1, 1],\n",
    "                 padding_list = [0,0], pool_kernel_list = [2, 2],\n",
    "                 pool_stride_list = [2, 2],\n",
    "                 pooling_list = [nn.MaxPool2d, nn.MaxPool2d], activations_list = [nn.ReLU(), nn.ReLU()])\n",
    "optimizerSGDlargerKernels = torch.optim.SGD(cnnDynamiclargerKernels.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestAccuracyOriginal, totalIterationsOriginal = doTheThing(cnnDynamicOG, optimizerSGD)\n",
    "# bestAccuracyWithAdam, totalIterationsWithAdam = doTheThing(cnnDynamicOG, optimizerAdam)\n",
    "bestAccuracyWithLargerKernels, totalIterationsWithLargerKernels = doTheThing(cnnDynamiclargerKernels, optimizerSGDlargerKernels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"With the original settings, the best accuracy achieved was {}, after {} iterations.\".format(bestAccuracyOriginal, totalIterationsOriginal))\n",
    "print(\"Using Adam as the optimizer, the best accuracy achieved was {}, after {} iterations.\".format(bestAccuracyWithAdam, totalIterationsWithAdam))\n",
    "print(\"With a larger kernel size, the best accuracy achieved was {}, after {} iterations.\".format(bestAccuracyWithLargerKernels, totalIterationsWithLargerKernels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
